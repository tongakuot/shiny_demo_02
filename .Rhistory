runApp()
View(ds_tbl)
runApp()
runApp()
runApp()
runApp()
knitr::opts_chunk$set(
echo    = TRUE,
message = FALSE,
warning = FALSE)
# Libraries
library(tidyverse)
library(vroom)
library(bbplot)
# Import the data
path <- "https://media.githubusercontent.com/media/khuyentran1401/dataset/master/data_science_market/all_skills.csv"
data_raw <- vroom(path, show_col_types = FALSE)
# Inspect the first 15 rows
data_raw %>%
slice_head(n = 15)
ds_skills_data_tbl <-
# Raw data
data_raw %>%
# Select desired columns and rearrange them
select(Title, skill, count) %>%
# Modify column names
set_names(names(.) %>% str_to_lower())
View(ds_skills_data_tbl)
runApp()
runApp()
# Subset the data
ds_skills_data_tbl <-
# Raw data
data_raw %>%
# Select desired columns and rearrange them
select(Title, skill, count) %>%
# Modify column names
set_names(names(.) %>% str_to_lower()) %>%
# Tidy skill column values
mutate(
skill = case_when(
str_detect(skill, 'sql')                                  ~ 'sql',
str_detect(skill, 'database')                             ~ 'databases',
str_detect(skill, 'etl')                                  ~ 'etl',
skill %in% c('phython', 'python (programming language)')  ~ 'python',
str_detect(skill, 'excel')                                ~ 'microsoft excel',
str_detect(skill, 'cisco')                                ~ 'cisco technologies',
skill == 'access'                                         ~ 'microsoft access',
skill == 'word'                                           ~ 'microsoft word',
skill %in% c('power point', 'powerpoint')                 ~ 'microsoft powerpoint',
skill %in% c('natural language processing (nlp)', 'nlp')  ~ 'natural language processing',
skill == 'requirements analysis'                          ~ 'requirement analysis',
skill == 'sas programming'                                ~ 'sas',
skill == 'jupyter'                                        ~ 'jupyter notebook',
skill == 'artificial intelligence (ai)'                   ~ 'artificial intelligence',
skill == 'cloud'                                          ~ 'cloud computing',
str_detect(skill, 'data structure')                       ~ 'data structures',
str_detect(skill, 'data warehousing')                     ~ 'datawarehouse',
skill == 'model'                                          ~ 'modeling',
str_detect(skill, 'visio')                                ~ 'microsoft visio',
skill == 'networking skills'                              ~ 'networking',
skill == 'pandas (software)'                              ~ 'pandas',
TRUE ~ skill)
) %>%
# Group by title, skill, and summarize
group_by(
title, skill
) %>%
summarize(
count   = sum(count),
.groups = "drop"
) %>%
# Add data label column
mutate(
label = str_glue("{title} ({skill}): {count}")
)
View(ds_skills_data_tbl)
View(data_raw)
ds_skills_data_tbl$skill %>% unique() %>% sort()
# Subset the data
ds_skills_data_tbl <-
# Raw data
data_raw %>%
# Select desired columns and rearrange them
select(Title, skill, count) %>%
# Modify column names
set_names(names(.) %>% str_to_lower()) %>%
# Tidy skill column values
mutate(
skill = case_when(
str_detect(skill, 'sql')                                  ~ 'sql',
str_detect(skill, 'database')                             ~ 'databases',
str_detect(skill, 'etl')                                  ~ 'etl',
skill %in% c('phython', 'python (programming language)')  ~ 'python',
str_detect(skill, 'excel')                                ~ 'microsoft excel',
str_detect(skill, 'cisco')                                ~ 'cisco technologies',
skill == 'access'                                         ~ 'microsoft access',
skill == 'word'                                           ~ 'microsoft word',
skill %in% c('power point', 'powerpoint')                 ~ 'microsoft powerpoint',
skill %in% c('natural language processing (nlp)', 'nlp')  ~ 'natural language processing',
skill == 'requirements analysis'                          ~ 'requirement analysis',
skill == 'sas programming'                                ~ 'sas',
skill == 'jupyter'                                        ~ 'jupyter notebook',
skill == 'artificial intelligence (ai)'                   ~ 'artificial intelligence',
skill == 'cloud'                                          ~ 'cloud computing',
str_detect(skill, 'data structure')                       ~ 'data structures',
str_detect(skill, 'datawarehouse')                        ~ 'data warehousing',
skill == 'model'                                          ~ 'modeling',
str_detect(skill, 'visio')                                ~ 'microsoft visio',
skill == 'networking skills'                              ~ 'networking',
skill == 'pandas (software)'                              ~ 'pandas',
TRUE ~ skill)
) %>%
# Group by title, skill, and summarize
group_by(
title, skill
) %>%
summarize(
count   = sum(count),
.groups = "drop"
) %>%
# Add data label column
mutate(
label = str_glue("{title} ({skill}): {count}")
) %>%
# Remove undesired skills
filter(
skill %in% c("amazon web services (aws)", "apache spark",
"artificial intelligence", "big data", "business analysis",
"business intelligence", "c", "c#", "c++", "cloud computing",
"css", "data analysis", "data mining", "data science",
"data modeling", "data visualization", "databases",
"deep learning", "data warehousing", "django", "docker",
"etl", "financial analysis", "git", "hive", "hadoop",
"html5", "html", "java", "jupyter notebook", "javascript",
"integration", "latex", "keras", "linux",  "machine learning",
"mathematical modeling", "mathematics", "matlab",
"microsoft excel", "microsoft office", "microsoft powerpoint",
"microsoft word", "mongodb", "natural language processing",
"numpy", "opencv", "node.js", "neural networks", "pandas",
"python", "pytorch", "r", "sas", "scala", "scikit-learn",
"shell scripting", "software development", "spark", "spss",
"software engineering",  "sql", "statistical data analysis",
"statistical modeling", "statistics", "tableau", "tensorflow",
"time management",  "writing", "mathematics", "advanced calculus")
)
View(ds_skills_data_tbl)
# Save data as a CSV file
vroom::vroom_write(ds_skills_data_tbl,
'../00_data/ds_tbl.csv',
delim = ',')
# Load the dataset
ds_tbl <- vroom::vroom('00_data/ds_tbl.csv', show_col_types = FALSE)
majors_tbl <- vroom::vroom('00_data/majors_tbl.csv', show_col_types = FALSE)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("plotly")
library(plotly)
runApp()
runApp()
runApp()
runApp()
runApp()
library(plotly)
runApp()
runApp()
runApp()
runApp()
?selectInput
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("DT")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
ds_tbl %>% group_by(title) %>% mutate(max_n = n()
ds_tbl %>% group_by(title) %>% mutate(max_n = n()
ds_tbl %>% group_by(title) %>% mutate(max_n = n())
ds_tbl %>% group_by(title) %>% mutate(max_n = n())
runApp()
runApp()
ds_max_n <- ds_tbl %>% group_by(title) %>% mutate(max_n = n())
View(ds_max_n)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?scale_x_discrete
runApp()
runApp()
runApp()
runApp()
View(majors_tbl)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
# Import majors dataset
majors_data_tbl <- vroom('../00_data/majors_data.csv') %>%
# Select desired columns
select(title, major = name, freq = value) %>%
# Modify major names to wrap around
mutate(
title = str_to_title(title),
major = str_wrap(major, width = 80)
)
View(majors_data_tbl)
# Save as a CSV file
majors_data_tbl %>% vroom_write('../00_data/majors_tbl.csv', delim = ',')
majors_tbl <- vroom::vroom('00_data/majors_tbl.csv', show_col_types = FALSE)
runApp()
runApp()
runApp()
# Import majors dataset
majors_data_tbl <- vroom('../00_data/majors_data.csv') %>%
# Select desired columns
select(title, major = name, freq = value) %>%
# Modify major names to wrap around
mutate(
major = ifelse(major == 'business administration and management, general',
'business admin. and management, general', major)
)
# Save as a CSV file
majors_data_tbl %>% vroom_write('../00_data/majors_tbl.csv', delim = ',')
majors_tbl <- vroom::vroom('00_data/majors_tbl.csv', show_col_types = FALSE)
runApp()
# Import majors dataset
majors_data_tbl <- vroom('../00_data/majors_data.csv') %>%
# Select desired columns
select(title, major = name, freq = value) %>%
# Modify major names to wrap around
mutate(
major = ifelse(major == 'business administration and management, general',
'business admin. and management, general', major),
title = str_to_title(title)
)
# Save as a CSV file
majors_data_tbl %>% vroom_write('../00_data/majors_tbl.csv', delim = ',')
majors_tbl <- vroom::vroom('00_data/majors_tbl.csv', show_col_types = FALSE)
runApp()
# Import majors dataset
majors_data_tbl <- vroom('../00_data/majors_data.csv') %>%
# Select desired columns
select(title, major = name, freq = value) %>%
# Modify major names to wrap around
mutate(
major = ifelse(major == 'business administration and management, general',
'business admin. and management, general', major),
title = str_to_title(title)
) %>%
arrange(title)
# Save as a CSV file
majors_data_tbl %>% vroom_write('../00_data/majors_tbl.csv', delim = ',')
majors_tbl <- vroom::vroom('00_data/majors_tbl.csv', show_col_types = FALSE)
runApp()
# Import majors dataset
majors_data_tbl <- vroom('../00_data/majors_data.csv') %>%
# Select desired columns
select(title, major = name, freq = value) %>%
# Modify major names to wrap around
mutate(
major = case_when(
major == 'business administration and management, general' ~ 'business admin. and management, general',
major == 'electrical, electronics and comm engineering'
TRUE ~ major),
# Import majors dataset
majors_data_tbl <- vroom('../00_data/majors_data.csv') %>%
# Select desired columns
select(title, major = name, freq = value) %>%
# Modify major names to wrap around
mutate(
major = case_when(
major == 'business administration and management, general' ~ 'business admin. and management, general',
major == 'electrical, electronics and communications engineering' ~ 'electrical, electronics and communications engineering',
TRUE ~ major),
title = str_to_title(title)
) %>%
arrange(title)
# Save as a CSV file
majors_data_tbl %>% vroom_write('../00_data/majors_tbl.csv', delim = ',')
majors_tbl <- vroom::vroom('00_data/majors_tbl.csv', show_col_types = FALSE)
runApp()
runApp()
# Import majors dataset
majors_data_tbl <- vroom('../00_data/majors_data.csv') %>%
# Select desired columns
select(title, major = name, freq = value) %>%
# Modify major names to wrap around
mutate(
title = str_to_title(title),
major = str_to_title(major)
) %>%
arrange(title)
# Save as a CSV file
majors_data_tbl %>% vroom_write('../00_data/majors_tbl.csv', delim = ',')
# Subset the data
ds_skills_data_tbl <-
# Raw data
data_raw %>%
# Select desired columns and rearrange them
select(Title, skill, count) %>%
# Modify column names
set_names(names(.) %>% str_to_lower()) %>%
# Tidy skill column values
mutate(
skill = case_when(
str_detect(skill, 'sql')                                  ~ 'sql',
str_detect(skill, 'database')                             ~ 'databases',
str_detect(skill, 'etl')                                  ~ 'etl',
skill %in% c('phython', 'python (programming language)')  ~ 'python',
str_detect(skill, 'excel')                                ~ 'microsoft excel',
str_detect(skill, 'cisco')                                ~ 'cisco technologies',
skill == 'access'                                         ~ 'microsoft access',
skill == 'word'                                           ~ 'microsoft word',
skill %in% c('power point', 'powerpoint')                 ~ 'microsoft powerpoint',
skill %in% c('natural language processing (nlp)', 'nlp')  ~ 'natural language processing',
skill == 'requirements analysis'                          ~ 'requirement analysis',
skill == 'sas programming'                                ~ 'sas',
skill == 'jupyter'                                        ~ 'jupyter notebook',
skill == 'artificial intelligence (ai)'                   ~ 'artificial intelligence',
skill == 'cloud'                                          ~ 'cloud computing',
str_detect(skill, 'data structure')                       ~ 'data structures',
str_detect(skill, 'datawarehouse')                        ~ 'data warehousing',
skill == 'model'                                          ~ 'modeling',
str_detect(skill, 'visio')                                ~ 'microsoft visio',
skill == 'networking skills'                              ~ 'networking',
skill == 'pandas (software)'                              ~ 'pandas',
TRUE ~ skill)
) %>%
# Group by title, skill, and summarize
group_by(
title, skill
) %>%
summarize(
count   = sum(count),
.groups = "drop"
) %>%
# Remove undesired skills
filter(
skill %in% c("amazon web services (aws)", "apache spark",
"artificial intelligence", "big data", "business analysis",
"business intelligence", "c", "c#", "c++", "cloud computing",
"css", "data analysis", "data mining", "data science",
"data modeling", "data visualization", "databases",
"deep learning", "data warehousing", "django", "docker",
"etl", "financial analysis", "git", "hive", "hadoop",
"html5", "html", "java", "jupyter notebook", "javascript",
"integration", "latex", "keras", "linux",  "machine learning",
"mathematical modeling", "mathematics", "matlab",
"microsoft excel", "microsoft office", "microsoft powerpoint",
"microsoft word", "mongodb", "natural language processing",
"numpy", "opencv", "node.js", "neural networks", "pandas",
"python", "pytorch", "r", "sas", "scala", "scikit-learn",
"shell scripting", "software development", "spark", "spss",
"software engineering",  "sql", "statistical data analysis",
"statistical modeling", "statistics", "tableau", "tensorflow",
"time management",  "writing", "mathematics", "advanced calculus")
) %>%
mutate(
skill = str_to_title(skill)
)
# Save data as a CSV file
vroom::vroom_write(ds_skills_data_tbl,
'../00_data/ds_tbl.csv',
delim = ',')
# Load the dataset
ds_tbl <- vroom::vroom('00_data/ds_tbl.csv', show_col_types = FALSE)
majors_tbl <- vroom::vroom('00_data/majors_tbl.csv', show_col_types = FALSE)
runApp()
# Subset the data
ds_skills_data_tbl <-
# Raw data
data_raw %>%
# Select desired columns and rearrange them
select(Title, skill, count) %>%
# Modify column names
set_names(names(.) %>% str_to_lower()) %>%
# Tidy skill column values
mutate(
skill = case_when(
str_detect(skill, 'sql')                                  ~ 'sql',
str_detect(skill, 'database')                             ~ 'databases',
str_detect(skill, 'etl')                                  ~ 'etl',
skill %in% c('phython', 'python (programming language)')  ~ 'python',
str_detect(skill, 'excel')                                ~ 'microsoft excel',
str_detect(skill, 'cisco')                                ~ 'cisco technologies',
skill == 'access'                                         ~ 'microsoft access',
skill == 'word'                                           ~ 'microsoft word',
skill %in% c('power point', 'powerpoint')                 ~ 'microsoft powerpoint',
skill %in% c('natural language processing (nlp)', 'nlp')  ~ 'natural language processing',
skill == 'requirements analysis'                          ~ 'requirement analysis',
skill == 'sas programming'                                ~ 'sas',
skill == 'jupyter'                                        ~ 'jupyter notebook',
skill == 'artificial intelligence (ai)'                   ~ 'artificial intelligence',
skill == 'cloud'                                          ~ 'cloud computing',
str_detect(skill, 'data structure')                       ~ 'data structures',
str_detect(skill, 'datawarehouse')                        ~ 'data warehousing',
skill == 'model'                                          ~ 'modeling',
str_detect(skill, 'visio')                                ~ 'microsoft visio',
skill == 'networking skills'                              ~ 'networking',
skill == 'pandas (software)'                              ~ 'pandas',
TRUE ~ skill)
) %>%
# Group by title, skill, and summarize
group_by(
title, skill
) %>%
summarize(
count   = sum(count),
.groups = "drop"
) %>%
# Remove undesired skills
filter(
skill %in% c("amazon web services (aws)", "apache spark",
"artificial intelligence", "big data", "business analysis",
"business intelligence", "c", "c#", "c++", "cloud computing",
"css", "data analysis", "data mining", "data science",
"data modeling", "data visualization", "databases",
"deep learning", "data warehousing", "django", "docker",
"etl", "financial analysis", "git", "hive", "hadoop",
"html5", "html", "java", "jupyter notebook", "javascript",
"integration", "latex", "keras", "linux",  "machine learning",
"mathematical modeling", "mathematics", "matlab",
"microsoft excel", "microsoft office", "microsoft powerpoint",
"microsoft word", "mongodb", "natural language processing",
"numpy", "opencv", "node.js", "neural networks", "pandas",
"python", "pytorch", "r", "sas", "scala", "scikit-learn",
"shell scripting", "software development", "spark", "spss",
"software engineering",  "sql", "statistical data analysis",
"statistical modeling", "statistics", "tableau", "tensorflow",
"time management",  "writing", "mathematics", "advanced calculus")
)
# Save data as a CSV file
vroom::vroom_write(ds_skills_data_tbl,
'../00_data/ds_tbl.csv',
delim = ',')
# Load the dataset
ds_tbl <- vroom::vroom('00_data/ds_tbl.csv', show_col_types = FALSE)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?number_format
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
View(ds_tbl)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
